---
title: "Gene Dependency Prediction Problem Set - Answer Key"
author: "Renan Escalante"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(vip)
library(glmnet)
```

## 1. Load and prepare the dataset

```{r load_data}
# Load the dataset
data <- read_csv(here::here("class_4_linear_regression/depmap/dependency_score_to_predict.csv"))

# Prepare the data
model_data <- data %>%
  select(cell_line = depmap_id, 
         dependency = crispr_dep_map_public_24q2_score_chronos, 
         everything(), 
         -cell_line_name, -primary_disease, -lineage, -lineage_subtype) %>%
  drop_na() %>%
  rename_with(~str_extract(., "^[A-Z0-9]+"), matches("^[A-Z0-9]+\\s\\(\\d+\\)$"))



print(paste("Number of samples:", nrow(model_data)))
print(paste("Number of predictors:", ncol(model_data) - 2))
```

## 2. Create a scatter plot of top correlated genes

```{r correlations}
# Calculate correlations
correlations <- model_data %>%
  select(-cell_line) %>%
  cor() %>%
  as.data.frame() %>%
  rownames_to_column("gene") %>%
  select(gene, correlation = dependency) %>%
  arrange(desc(abs(correlation)))

top_2_genes <- correlations %>% 
  dplyr::filter(gene != "dependency") %>% 
  slice_max(abs(correlation), n = 2) %>% 
  pull(gene)

ggplot(model_data, aes(x = .data[[top_2_genes[1]]], y = .data[[top_2_genes[2]]], color = dependency)) +
  geom_point() +
  scale_color_viridis_c() +
  labs(title = "Top 2 Correlated Genes vs Dependency",
       x = top_2_genes[1],
       y = top_2_genes[2])
```

## 3. Split the data

```{r split_data}
set.seed(123)
data_split <- initial_split(model_data, prop = 0.8, strata = dependency)
train_data <- training(data_split)
test_data <- testing(data_split)

print(paste("Training samples:", nrow(train_data)))
print(paste("Testing samples:", nrow(test_data)))
```

## 4. Create a recipe

```{r create_recipe}
lm_rec <- recipe(dependency ~ ., data = train_data) %>%
  update_role(cell_line, new_role = "ID") %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

print(lm_rec)
```

## 5. Fit a linear regression model

```{r fit_lm}
lm_spec <- linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

lm_wf <- workflow() %>% 
  add_recipe(lm_rec) %>% 
  add_model(lm_spec)
lm_fit <- lm_wf %>% fit(data = train_data)

top_coefficients <- lm_fit %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  slice_max(abs(estimate), n = 5)
print(top_coefficients)
```

## 6. Evaluate model performance

```{r evaluate_lm}
predictions <- lm_fit %>% predict(test_data) %>% bind_cols(test_data)
metrics <- predictions %>% metrics(truth = dependency, estimate = .pred)
metrics
```

## 7. Scatter plot of actual vs. predicted

```{r plot_predictions}
ggplot(predictions, aes(x = dependency, y = .pred)) +
  geom_point() +
  geom_abline(color = "red") +
  labs(title = "Actual vs Predicted Dependency Scores",
       x = "Actual", y = "Predicted")
```

## 8. Feature importance analysis

```{r feature_importance}
importance <- lm_fit %>%
  extract_fit_parsnip() %>%
  vip(n = 5)
print(importance)
```
## 9. How about testing a model with only a single parameter

```{r create_recipe}
lm_rec_SOX10 <- recipe(dependency ~ SOX10, data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

print(lm_rec_SOX10)
```
```{r}
lm_wf_SOX10 <- workflow() %>% 
  add_recipe(lm_rec_SOX10) %>% 
  add_model(lm_spec)
lm_fit_SOX10 <- lm_wf_SOX10 %>% fit(data = train_data)
```

```{r}
predictions_fit_SOX10 <- lm_fit_SOX10 %>% predict(test_data) %>% bind_cols(test_data)
predictions_fit_SOX10 %>% metrics(truth = dependency, estimate = .pred)
```



## 9. Set up tuning grid for regularized regression

```{r tuning_grid}
tune_spec <- linear_reg(penalty = tune(), mixture = tune()) %>% set_engine("glmnet")

tune_grid <- grid_regular(
  penalty(range = c(-5, 5), trans = transform_log10()),
  mixture(range = c(0, 1)),
  levels = list(penalty = 4, mixture = 3)
)

tune_grid
```

## 10. Perform cross-validation and tuning

```{r cv_tuning}
tune_wf <- workflow() %>% add_recipe(lm_rec) %>% add_model(tune_spec)

cv_folds <- vfold_cv(train_data, v = 5)

tune_results <- tune_grid(
  tune_wf,
  resamples = cv_folds,
  grid = tune_grid,
  metrics = metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae)
)
```

```{r}
metrics_df <- tune_results %>% collect_metrics()
```


```{r}
best_params <- tune_results %>% select_best(metric = "rmse")
print(best_params)
```

```{r}
autoplot(tune_results)
```


## 11. Fit final regularized regression model

```{r fit_reg_model}
final_wf <- tune_wf %>% finalize_workflow(best_params)
final_fit <- final_wf %>% fit(data = train_data)

reg_predictions <- final_fit %>% predict(test_data) %>% bind_cols(test_data)
reg_metrics <- reg_predictions %>% metrics(truth = dependency, estimate = .pred)
print(reg_metrics)
```




## 12. Variable importance plot for regularized regression

```{r reg_importance}
reg_importance <- final_fit %>%
  extract_fit_parsnip() %>%
  vip(n = 10)
print(reg_importance)
```


```{r}
top_coefficients_final <- final_fit %>%
  extract_fit_parsnip() %>%
  tidy()

top_coefficients_final %>% 
  dplyr::filter(estimate > 0)
```



